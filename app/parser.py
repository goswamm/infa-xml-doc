import xml.etree.ElementTree as ET\nimport pandas as pd\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom textwrap import wrap\n\ndef findall(elem, tag):\n    return elem.findall(f\".//{tag}\") if elem is not None else []\n\ndef findfirst(elem, tag):\n    return elem.find(f\".//{tag}\") if elem is not None else None\n\ndef parse_xml_bytes(xml_bytes: bytes):\n    root = ET.fromstring(xml_bytes)\n\n    repo = findfirst(root, \"REPOSITORY\")\n    folder = findfirst(root, \"FOLDER\")\n    mapping = findfirst(root, \"MAPPING\")\n    workflow = findfirst(root, \"WORKFLOW\")\n    session = findfirst(workflow, \"SESSION\") if workflow is not None else None\n\n    overview = {\n        \"Repository\": repo.get(\"NAME\") if repo is not None else \"\",\n        \"Folder\": folder.get(\"NAME\") if folder is not None else \"\",\n        \"Mapping Name\": mapping.get(\"NAME\") if mapping is not None else \"\",\n        \"Workflow Name\": workflow.get(\"NAME\") if workflow is not None else \"\",\n        \"Session Name\": session.get(\"NAME\") if session is not None else \"\",\n    }\n\n    source_rows = []\n    sources = findall(folder, \"SOURCE\")\n    for s in sources:\n        s_name = s.get(\"NAME\")\n        s_type = s.get(\"DATABASETYPE\")\n        for sf in findall(s, \"SOURCEFIELD\"):\n            source_rows.append({\n                \"Source Name\": s_name,\n                \"Source Type\": s_type,\n                \"Field Name\": sf.get(\"NAME\"),\n                \"Datatype\": sf.get(\"DATATYPE\"),\n                \"Length/Precision\": sf.get(\"PRECISION\"),\n                \"Scale\": sf.get(\"SCALE\"),\n                \"Nullable\": sf.get(\"NULLABLE\"),\n            })\n    source_df = pd.DataFrame(source_rows)\n\n    target_rows = []\n    targets = findall(folder, \"TARGET\")\n    target_name = targets[0].get(\"NAME\") if targets else \"TARGET_TABLE\"\n    for t in targets:\n        t_name = t.get(\"NAME\")\n        t_type = t.get(\"DATABASETYPE\")\n        for tf in findall(t, \"TARGETFIELD\"):\n            target_rows.append({\n                \"Target Name\": t_name,\n                \"Database\": t_type,\n                \"Column\": tf.get(\"NAME\"),\n                \"Datatype\": tf.get(\"DATATYPE\"),\n                \"Precision\": tf.get(\"PRECISION\"),\n                \"Scale\": tf.get(\"SCALE\"),\n                \"Key Type\": tf.get(\"KEYTYPE\"),\n                \"Nullable\": tf.get(\"NULLABLE\"),\n            })\n    target_df = pd.DataFrame(target_rows)\n\n    trans_rows = []\n    if mapping is not None:\n        for tr in findall(mapping, \"TRANSFORMATION\"):\n            tr_name = tr.get(\"NAME\")\n            tr_type = tr.get(\"TYPE\")\n            for tf in findall(tr, \"TRANSFORMFIELD\"):\n                trans_rows.append({\n                    \"Transformation\": tr_name,\n                    \"Type\": tr_type,\n                    \"Port Name\": tf.get(\"NAME\"),\n                    \"Port Type\": tf.get(\"PORTTYPE\"),\n                    \"Datatype\": tf.get(\"DATATYPE\"),\n                    \"Precision\": tf.get(\"PRECISION\"),\n                    \"Scale\": tf.get(\"SCALE\"),\n                    \"Default\": tf.get(\"DEFAULTVALUE\"),\n                    \"Expression\": tf.get(\"EXPRESSION\") if tf.get(\"EXPRESSION\") else \"\",\n                })\n            for ta in findall(tr, \"TABLEATTRIBUTE\"):\n                if ta.get(\"NAME\") in (\"Lookup Sql Override\",\"Lookup condition\",\"Lookup table name\"):\n                    trans_rows.append({\n                        \"Transformation\": tr_name,\n                        \"Type\": tr_type,\n                        \"Port Name\": ta.get(\"NAME\"),\n                        \"Port Type\": \"Attribute\",\n                        \"Datatype\": \"\",\n                        \"Precision\": \"\",\n                        \"Scale\": \"\",\n                        \"Default\": \"\",\n                        \"Expression\": ta.get(\"VALUE\"),\n                    })\n    trans_df = pd.DataFrame(trans_rows)\n\n    conn_rows = []\n    if mapping is not None:\n        for c in findall(mapping, \"CONNECTOR\"):\n            conn_rows.append({\n                \"From Instance\": c.get(\"FROMINSTANCE\"),\n                \"From Type\": c.get(\"FROMINSTANCETYPE\"),\n                \"From Field\": c.get(\"FROMFIELD\"),\n                \"To Instance\": c.get(\"TOINSTANCE\"),\n                \"To Type\": c.get(\"TOINSTANCETYPE\"),\n                \"To Field\": c.get(\"TOFIELD\"),\n            })\n    conn_df = pd.DataFrame(conn_rows)\n\n    lineage_rows = []\n    for _, row in conn_df.iterrows():\n        if row.get(\"To Type\") == \"Target Definition\":\n            lineage_rows.append({\n                \"Target Table\": target_name,\n                \"Target Column\": row.get(\"To Field\"),\n                \"Comes From Instance\": row.get(\"From Instance\"),\n                \"Comes From Field\": row.get(\"From Field\"),\n            })\n    lineage_df = pd.DataFrame(lineage_rows)\n\n    session_attrs = {}\n    if session is not None:\n        for attr in findall(session, \"ATTRIBUTE\"):\n            k = attr.get(\"NAME\")\n            v = attr.get(\"VALUE\")\n            session_attrs[k] = v\n    session_attrs_df = pd.DataFrame([session_attrs]) if session_attrs else pd.DataFrame()\n\n    overview_df = pd.DataFrame(list(overview.items()), columns=[\"Item\", \"Value\"])\n\n    tabs = {\n        \"Overview\": overview_df,\n        \"Source Fields\": source_df,\n        \"Target Fields\": target_df,\n        \"Field Lineage\": lineage_df,\n        \"Transformations\": trans_df,\n        \"Connectors\": conn_df,\n        \"Reader Settings\": pd.DataFrame(),\n        \"Writer Settings\": pd.DataFrame(),\n        \"Session Attributes\": session_attrs_df,\n    }\n\n    meta = {\n        \"target_name\": target_name,\n        \"mapping_name\": overview[\"Mapping Name\"],\n        \"workflow_name\": overview[\"Workflow Name\"],\n        \"source_headers\": list(source_df[\"Field Name\"].unique()) if not source_df.empty else []\n    }\n    return tabs, meta\n\ndef write_excel_bytes(tabs: dict) -> bytes:\n    output = BytesIO()\n    with pd.ExcelWriter(output, engine=\"xlsxwriter\") as xlw:\n        for name, df in tabs.items():\n            if df is None or df.empty:\n                continue\n            sheet_name = name[:31]\n            df.to_excel(xlw, index=False, sheet_name=sheet_name)\n    output.seek(0)\n    return output.read()\n\ndef oracle_type(datatype, precision, scale):\n    dt = (str(datatype) or \"\").upper()\n    precision = str(precision) if precision is not None else \"\"\n    scale = str(scale) if scale is not None else \"\"\n    if dt in (\"VARCHAR\", \"VARCHAR2\"):\n        if precision.isdigit():\n            return f\"VARCHAR2({precision})\"\n        return \"VARCHAR2(255)\"\n    if dt == \"CHAR\":\n        if precision.isdigit():\n            return f\"CHAR({precision})\"\n        return \"CHAR(1)\"\n    if dt in (\"NUMBER\",\"DECIMAL\",\"NUMERIC\",\"INTEGER\",\"INT\",\"SMALLINT\"):\n        if precision.isdigit():\n            if scale.isdigit():\n                return f\"NUMBER({precision},{scale})\"\n            return f\"NUMBER({precision})\"\n        return \"NUMBER\"\n    if dt == \"DATE\":\n        return \"DATE\"\n    if dt.startswith(\"TIMESTAMP\"):\n        return \"TIMESTAMP\"\n    return \"VARCHAR2(255)\"\n\ndef build_target_sql(meta: dict, target_df: pd.DataFrame) -> str:\n    tname = meta.get(\"target_name\") or \"TARGET_TABLE\"\n    cols = []\n    pk_cols = []\n    if target_df is None or target_df.empty:\n        return f\"/* No target found in XML; create your table manually: {tname} */\"\n    for _, r in target_df.iterrows():\n        colname = r.get(\"Column\")\n        dtype = oracle_type(r.get(\"Datatype\"), r.get(\"Precision\"), r.get(\"Scale\"))\n        nullable = \"\" if (str(r.get(\"Nullable\")).upper() == \"NOTNULL\") else \" NULL\"\n        cols.append(f\"  {colname} {dtype}{nullable}\")\n        if str(r.get(\"Key Type\")).upper() == \"PRIMARY KEY\":\n            pk_cols.append(colname)\n    lines = [f\"CREATE TABLE {tname} (\", \",\\n\".join(cols), \");\"]\n    if pk_cols:\n        lines.append(f\"ALTER TABLE {tname} ADD CONSTRAINT PK_{tname} PRIMARY KEY ({', '.join(pk_cols)});\")\n    return \"\\n\".join(lines)\n\ndef hex_to_rgb_tuple(hex_color: str):\n    hex_color = hex_color.strip().lstrip(\"#\")\n    if len(hex_color) == 3:\n        hex_color = \"\".join([c*2 for c in hex_color])\n    if len(hex_color) != 6:\n        return (138/255, 30/255, 2/255)\n    r = int(hex_color[0:2], 16)/255.0\n    g = int(hex_color[2:4], 16)/255.0\n    b = int(hex_color[4:6], 16)/255.0\n    return (r, g, b)\n\ndef build_pdf_bytes(meta: dict, tabs: dict,\n                    brand_name=\"VAAMG Consulting\",\n                    brand_tagline=\"Agile in Mind. Enterprise in Delivery.\",\n                    brand_hex=\"#8a1e02\") -> bytes:\n    mapping = meta.get(\"mapping_name\", \"\")\n    workflow = meta.get(\"workflow_name\", \"\")\n    target = meta.get(\"target_name\", \"\")\n    headers = meta.get(\"source_headers\", [])\n    tgt_cols = []\n    if \"Target Fields\" in tabs and not tabs[\"Target Fields\"].empty:\n        tgt_cols = list(tabs[\"Target Fields\"][\"Column\"].astype(str).values)\n\n    fig = plt.figure(figsize=(8.27, 11.69))\n    ax = plt.axes([0,0,1,1])\n    ax.axis('off')\n\n    brand_rgb = hex_to_rgb_tuple(brand_hex or \"#8a1e02\")\n    header_height = 0.12\n    ax.add_patch(Rectangle((0, 1-header_height), 1, header_height, color=brand_rgb))\n\n    ax.text(0.05, 0.965, brand_name, color=\"white\", fontsize=20, va='top', ha='left', weight='bold')\n    ax.text(0.05, 0.935, brand_tagline, color=\"white\", fontsize=11, va='top', ha='left')\n\n    ax.text(0.05, 0.84, \"Informatica Mapping â€“ Business Summary\", fontsize=16, weight='bold', ha='left', va='top')\n\n    overview_lines = [\n        f\"Mapping: {mapping}\",\n        f\"Workflow: {workflow}\",\n        f\"Source headers: {', '.join(headers) if headers else '(none found)'}\",\n        f\"Target table: {target}\",\n        f\"Target columns: {', '.join(tgt_cols)}\" if tgt_cols else \"Target columns: (none found)\",\n        \"Business highlights:\",\n        \" â€¢ Trims key identifiers prior to load (if defined in expressions)\",\n        \" â€¢ Integration ID derivations and HR lookups (if present in XML)\",\n        \" â€¢ Typical load settings: bulk insert / truncate-before-load (if set in session attributes)\",\n    ]\n    wrapped = []\n    for ln in overview_lines:\n        if len(ln) > 110:\n            wrapped.extend(wrap(ln, 110))\n        else:\n            wrapped.append(ln)\n    body_text = \"\\n\".join(wrapped)\n    ax.text(0.05, 0.80, body_text, fontsize=11, va='top', ha='left')\n\n    ax.text(0.05, 0.06, \"Auto-generated from Informatica XML\", fontsize=9, color=\"gray\", ha='left', va='bottom')\n    ax.text(0.95, 0.06, brand_name, fontsize=9, color=\"gray\", ha='right', va='bottom')\n\n    bio = BytesIO()\n    fig.savefig(bio, format=\"pdf\", bbox_inches=\"tight\")\n    plt.close(fig)\n    bio.seek(0)\n    return bio.read()\n